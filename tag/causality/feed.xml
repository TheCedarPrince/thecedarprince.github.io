<?xml version="1.0" encoding="UTF-8"?>

<rss version="2.0"
  xmlns:content="http://purl.org/rss/1.0/modules/content/"
  xmlns:dc="http://purl.org/dc/elements/1.1/"
  xmlns:media="http://search.yahoo.com/mrss/"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:georss="http://www.georss.org/georss">

  <channel>
    <title>
      <![CDATA[  the cedar ledge  ]]>
    </title>
    <link> https://jacobzelko.com </link>
    <description>
      <![CDATA[  Jacob S. Zelko&#39;s personal website  ]]>
    </description>
    <atom:link
      href="https://jacobzelko.com/feed.xml"
      rel="self"
      type="application/rss+xml" />


<item>
  <title>
    <![CDATA[  The Book of Why  ]]>
  </title>
  <link> https://jacobzelko.com/01072021082043-book-of-why/index.html </link>
  <guid> https://jacobzelko.com/01072021082043-book-of-why/index.html </guid>
  <description>
    <![CDATA[  How causality gives us tools to understand the question of cause-and-effect and confounders  ]]>
  </description>  
  
  <content:encoded>
    <![CDATA[  
<h1>The Book of Why</h1>
<p><strong>Date:</strong> January 7 2021</p>
<p><strong>Summary:</strong> How causality gives us tools to understand the question of cause-and-effect and confounders</p>
<p><strong>Keywords:</strong> ##bibliography #causality #diagrams #counterfactual #statistics #graphs ##book ##blog #archive</p>
<h1>Bibliography</h1>
<p>J. Pearl and D. Mackenzie, The book of why: the new science of cause and effect, First edition. New York: Basic Books, 2018.</p>
<h1>Table of Contents</h1>
<div class="franklin-toc"><ol><li><ol><li>Benefits of Causal Analysis</li><li>Critiques of Statistics</li><li>Causal Calculus</li><li>Inference Engine</li><li>Ladder of Causality</li><li>Mini-Turing Test</li><li>Bayesian Analysis</li><li>Causal Diagrams<ol><li>Paths in Path Diagrams<ol><li>Chain junction</li><li>Fork Junction</li><li>Collider Junction</li></ol></li><li>Lessons from Path Diagrams</li></ol></li></ol></li><li>How To Cite</li><li>References</li><li>Discussion: </li></ol></div>
<p>This book shows that data is stupid. Data can record events but cannot answer why any of the events are the way they are.</p>
<p>Causal inference posits the brain as the most advanced tool for understanding cause and effect.</p>
<p>Forcing an occurrence means to submit it to one influence to trigger the desired event</p>
<p><strong>Counterfactual:</strong> When scientific inquiry involves retrospective reflection. &quot;Why?&quot; is a counterfactual question.</p>
<p>Probabilities encode our beliefs about a static world. Causality explains probabilities in a changing world.</p>
<h3 id="benefits_of_causal_analysis">Benefits of Causal Analysis</h3>
<p>Create a smoother human-machine interface.</p>
<p><em>THOUGHTS: I wonder if that is what attracted me to the idea of Causal Inference - that it enables better human-machine interfaces. Like human-machine interaction as a discipline; I wonder if they have much in this area. Perhaps reach out to Valentine Wilson about the question?</em></p>
<h3 id="critiques_of_statistics">Critiques of Statistics</h3>
<p>Galton separated causation from statistics in 1889 causing the two separate fields to fully manifest.</p>
<p>&quot;Granger causality&quot; and &quot;vector autocorrelation&quot; exists to accommodate for causal explanations. Associated Thoughts: Judea&#39;s critique on probability-based causality</p>
<h3 id="causal_calculus">Causal Calculus</h3>
<p>Causal calculus uses two communications forms: </p>
<ol>
<li><p>Causal Diagrams: communicates what is known.</p>
</li>
<li><p>Symbolic language: defines what is wanted to be known</p>
</li>
</ol>
<h3 id="inference_engine">Inference Engine</h3>
<p>The inference engine assumes perfect and unlimited data for the given figure:</p>
<p><img src="https://jacobzelko.com/assets/01082021030619-inference-engine.png" alt="" /></p>
<p><strong>Estimand:</strong> generalized mathematical formula to answer data questions. A statistical quantity estimated from data that can represent an answer to a query.</p>
<p>A given estimand is computed on the basis of the causal model alone, prior to an examination of the specifics of the data. This gives the inference engine better adaptibility.</p>
<p><strong>Binary Evaluation of Query:</strong> determines if a query can be answered under an existing causal model.</p>
<p><strong>Knowledge:</strong> experience from the past such as prior observations and education.</p>
<p><strong>Assumptions:</strong> explicit statements from available Knowledge.</p>
<p><strong>Queries:</strong> the scientific questions to be answered.</p>
<p><strong>Testable Implications:</strong> observable patterns or dependencies resulting from the listening pattern of a causal model.</p>
<p><strong>Estimate:</strong> Estimate for the answer is determined alongside uncertainty metrics.The metrics reflect limited data, measurement errors, or missing data.</p>
<h3 id="ladder_of_causality">Ladder of Causality</h3>
<p>First rung: observation. This concerns recognition of patterns. This rung asks, &quot;What if I see ...?&quot;</p>
<p>The second rung: Doing. Altering an environment to achieve a certain goal. This rung poses the questions of &quot;What if we do...?&quot; or &quot;How?&quot;</p>
<h3 id="mini-turing_test">Mini-Turing Test</h3>
<p>Mini-Turing Test: Encode a simple story on a machine and see if it can answer causal questions a human can answer.</p>
<p>Rules:</p>
<ol>
<li><p>Limited only to causal reasoning and language.</p>
</li>
<li><p>The story can be encoded in the easiest way for the programmer.</p>
</li>
</ol>
<h3 id="bayesian_analysis">Bayesian Analysis</h3>
<p>Simplified Bayesian analysis: prior belief &#43; new evidence &#61; revised belief.</p>
<p>Bayesian inference enables one to express personal experiences mathematically and combine it with data in a principled and transparent way.</p>
<h3 id="causal_diagrams">Causal Diagrams</h3>
<p>&quot;Causation&quot; via a causal diagram is straightforward. A variable X is a cause of Y if Y listens to X. Y&#39;s value is determined by what it hears.</p>
<h4 id="paths_in_path_diagrams">Paths in Path Diagrams</h4>
<h5 id="chain_junction">Chain junction</h5>
\[
A \rightarrow B \rightarrow C
\]
<p>B is the mediator which relays the effect of A to C. B filters information about A from C.</p>
<h5 id="fork_junction">Fork Junction</h5>
\[
A \leftarrow B \rightarrow C
\]
<p>B is a confounder of A and C. B makes A and C statistically correlated despite no direct link between them.</p>
<h5 id="collider_junction">Collider Junction</h5>
\[
A \rightarrow B \leftarrow C
\]
<p>Conditioning on B will make A and C dependent</p>
<h4 id="lessons_from_path_diagrams">Lessons from Path Diagrams</h4>
<ol>
<li><p>Causal analysis allows us to quantify real world processes</p>
</li>
<li><p>Path analysis draws conclusions about individual causal relationships by examining the diagram as a whole.</p>
</li>
<li><p>Two people creating differing causal diagrams for the same data and may not arrive at the same result.</p>
</li>
</ol>
<h2 id="how_to_cite">How To Cite</h2>
<p>Zelko, Jacob. <em>The Book of Why</em>. <a href="https://jacobzelko.com/01072021082043-book-of-why">https://jacobzelko.com/01072021082043-book-of-why</a>. January 7 2021.</p>
<h2 id="references">References</h2>
<h2 id="discussion">Discussion: </h2>
<script>talkyardServerUrl='https://site-vbm8wbc57o.talkyard.net';</script>
<script async defer src="https://c1.ty-cdn.net/-/talkyard-comments.min.js"></script>
<div class="talkyard-comments" data-discussion-id="" style="margin-top: 45px;">
    <noscript>Please enable Javascript to view comments.</noscript>
</div> ]]>
  </content:encoded>
    
  <pubDate>Thu, 07 Jan 2021 00:00:00 +0000</pubDate>  
  
  
  <atom:author>
    <atom:name>Jacob Zelko</atom:name>
  </atom:author>
        
</item>

<item>
  <title>
    <![CDATA[  Causality and Information Retrieval  ]]>
  </title>
  <link> https://jacobzelko.com/03212020002114-causality-information/index.html </link>
  <guid> https://jacobzelko.com/03212020002114-causality-information/index.html </guid>
  <description>
    <![CDATA[  Thoughts on why I think JITRs are inferior to causal models.  ]]>
  </description>  
  
  <content:encoded>
    <![CDATA[  
<h1>Causality and Information Retrieval</h1>
<p><strong>Date:</strong> March 21 2020</p>
<p><strong>Summary:</strong> Thoughts on why I think JITRs are inferior to causal models.</p>
<p><strong>Keywords:</strong> ##zettel #justintime #informationretrieval #jitrs #causality #reasoning #ai #agi #archive</p>
<h1>Bibliography</h1>
<p>Not Available</p>
<h1>Table of Contents</h1>
<div class="franklin-toc"><ol><li>How To Cite</li><li>References</li><li>Discussion: </li></ol></div>
<p>I think Remembrance and Just In-Time Information Retrieval Agents &#40;nicknamed JITRs&#41; &#91;1&#93;, &#91;2&#93; partially – maybe by about 75&#37; – miss the point of truly aiding the human mind. On the surface, these tools come close to mimicking the chain of sub-thoughts and actions associated with a thought. A chain of thought being described in the following example: </p>
<pre><code class="language-julia">Thought: I wonder if I need my umbrella for today?
Goal: Find out if I need my umbrella for the day.Sub-Thought 1: I wonder what the weather is like for today?
Sub-Thought 2: I wonder what the probability of rain is for today?
Sub-Thought 3: I wonder where I should find this information?Action 1: Person searches for weather forecast on internet.
Action 2: Person finds local weather forecast.
Action 3: Person identifies chance of rain.Information Retrieved: There is a 75&#37; chance of rain today.Conclusion: I need my umbrella</code></pre>
<p>However, JITRs best option is to guess at what the eventual end goal of a chain of thought is but it has to forego guessing the sub-thoughts leading to the desired conclusion. I think that is why JITRs have found use, but I think it is the wrong problem to address. </p>
<p>In practice it is a very different approach, but I think to use causal modeling similar to what Judea Pearl posits is the better approach &#91;3&#93;, &#91;4&#93;.</p>
<p>Topically a JITR could watch you begin searching for allergies on a computer. Immediately, it delivers you results on common allergies. This could be useful but still is not the <em>most</em> useful as it is just guessing based on the search and some of the context of your search query. In actuality, you were trying to find information about the pollen level of your area for the day and if you should take your allergy medication prophylactically.</p>
<p>Instead, a causal agent might function similarly at first but instead of giving you a list of allergies, gives you more concise information. The causal agent infers, based on some history it has of you, you are worried if you should take your allergy medication that day. Instead, the agent just gives you information on pollen levels throughout the week based on local weather reports.</p>
<p>Though one can argue that there is guessing at place in either situation I think the latter proves far more effective than the former approach.</p>
<h2 id="how_to_cite">How To Cite</h2>
<p>Zelko, Jacob. <em>Causality and Information Retrieval</em>. <a href="https://jacobzelko.com/03212020002114-causality-information">https://jacobzelko.com/03212020002114-causality-information</a>. March 21 2020.</p>
<h2 id="references">References</h2>
<p>&#91;1&#93; B. J. Rhodes and P. Maes, “Just-in-time information retrieval agents,” IBM Syst. J., vol. 39, no. 3.4, pp. 685–704, 2000, doi: 10.1147/sj.393.0685.</p>
<p>&#91;2&#93; B. J. Rhodes and T. Starner, “Remembrance Agent: A Continuously Running Automated Information Retrieval System,” p. 4.</p>
<p>&#91;3&#93; L. Fridman, “Judea Pearl: Causal Reasoning, Counterfactuals, Bayesian Networks, and the Path to AGI | MIT | Artificial Intelligence Podcast,” Dec. 11, 2019. https://lexfridman.com/judea-pearl/ &#40;accessed Mar. 21, 2020&#41;.</p>
<p>&#91;4&#93; J. Pearl, Causality Models, Reasoning and Inference by Judea Pearl. 2009.</p>
<h2 id="discussion">Discussion: </h2>
<script>talkyardServerUrl='https://site-vbm8wbc57o.talkyard.net';</script>
<script async defer src="https://c1.ty-cdn.net/-/talkyard-comments.min.js"></script>
<div class="talkyard-comments" data-discussion-id="" style="margin-top: 45px;">
    <noscript>Please enable Javascript to view comments.</noscript>
</div> ]]>
  </content:encoded>
    
  <pubDate>Sat, 21 Mar 2020 00:00:00 +0000</pubDate>  
  
  
  <atom:author>
    <atom:name>Jacob Zelko</atom:name>
  </atom:author>
        
</item>
</channel></rss>