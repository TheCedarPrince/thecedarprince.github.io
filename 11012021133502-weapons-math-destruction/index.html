<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/basic.css"> <link rel=icon  href="/assets/favicon.png"> <title>Weapons of Math Destruction</title> <header> <div class=blog-name ><a href="/">the cedar ledge</a></div> <nav> <ul> <li><a href="/">Home</a> <li><a href="/blog">Blog</a> <li><a href="/archive">Archive</a> </ul> <img src="/assets/hamburger.svg" id=menu-icon > </nav> </header> <div class=franklin-content ><h1 id=weapons-of-math-destruction >Weapons of Math Destruction</h1> <p><strong>Date:</strong> November 01 2021</p> <p><strong>Summary:</strong></p> <p><strong>Keywords:</strong></p> <h2 id=bibliography >Bibliography</h2> <p>O’neil, C. (2016). Weapons of math destruction: How big data increases inequality and threatens democracy. Broadway Books.</p> <h2 id=notes >Notes</h2> <h3 id=quotes >Quotes</h3> <blockquote> <p>“Sometimes the job of a data scientist is to know when you don’t know enough.”</p> </blockquote> <h3 id=general-observations >General Observations</h3> <p>According to O’neil, profits have often come about to provide a stand-in as a value judgement on what is right or true. To that end, we are often vetted by algorithmically based on who we are (e.g. our backgrounds, race, etc.) and not on how we actually perform or fare.</p> <p>Model construction happens from:</p> <ol type=1 > <li>not just from data but from the choices we make about which data to pay attention to—and which to leave out. Those choices are not just about logistics, profits, and efficiency. They are fundamentally moral. We have to learn to interrogate our data collection process, not just our algorithms. </ol> <h3 id=credit-scores-as-a-proxy-for-human-value >Credit Scores as a Proxy for Human Value</h3> <p>When considering credit scores, money or wealth is no longer just about a means of survival. Wrapped up in these scores is also a value judgement on someone’s self-worth.</p> <p>Algorithms prioritize two factors: efficiency and profit. They do not care about justice or the well-being of the people underlying the data they are analyzing.</p> <h3 id=concluding-thoughts >Concluding Thoughts</h3> <p>So the first step is to get a grip on our techno-utopia, that unbounded and unwarranted hope in what algorithms and technology can accomplish. Before asking them to do better, we have to admit they can’t do everything</p> <p>audits have to be carefully designed and tested by human beings, and afterward automated</p> <h2 id=references >References:</h2> <div class=page-foot > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Jacob Zelko. Last modified: May 02, 2022. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div>